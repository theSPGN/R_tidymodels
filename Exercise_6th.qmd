---
title: "Tidymodels Exercise sixth"
author: "Mateusz Zajda"
format: 
  html:
    toc: true
    toc-title: "contents"
    number-depth: 5
    number-sections: true
    code-fold: show
    code-summary: "Hide/Show code"
    code-tools: true
    code-block-border-left: "black"
    code-line-numbers: true
    code-copy: true
    html-math-method: katex
    smooth-scroll: true
    self-contained: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme: 
      light: journal
      dark: darkly
    fontsize:  1.0em
    linestretch: 1.5
date: today
abstract-title: "About"
abstract: "Exercise **sixth**"
execute: 
  eval: true
  warning: false
  echo: true
  output: true
  error: false
editor_options: 
  chunk_output_type: console
---

```{=html}
<style type="text/css"> body {text-align: justify} </style>
```
## sixth exercise
o3 prediction using 3 different models

### Required packages
```{r}
# tidy data models library:
library(tidymodels)
# extension of ggplot2 for correlation graph:
library(GGally)
# data for model creation:
library(openair)
# data manipulation library:
library(dplyr)
# decision tree model library:
library(ranger)
# random forest model library:
library(rpart)
# linear regresion model library:
library(glmnet)
# model examination library:
library(yardstick)
# override with tidymodels functions:
tidymodels_prefer()
```

### Data preparation

```{r}
# selecting the data from 2002
air <-
    mydata |>
    selectByDate(year = 2002)

# removing rows with na value
air <-
    air |> na.omit()
```

### Changing wind direction into categorical data
```{r}
air <- 
    air |> mutate(
        wd = cut(
            wd,
            breaks = 16,
            labels = seq(1, 16)
        )
    )
```
### Air variables correlations

```{r}
#| label: ggpairs plot
#| layout-ncol: 1
#| fig-cap: "Drawing 1.1. ggpairs plot"
#| fig-cap-location: bottom
# correlation graph to examinate importance of variables and relations between them
air |> GGally::ggpairs()
```
### Splitting the data

```{r}
# setting seed for pseudorandom numbers
set.seed(222)

# splitting the data into the training nad testing partitions
data_split <- initial_split(
    data = air,
    prop = 3 / 4,
    strata = o3
)
train_data <- training(data_split)
test_data <- testing(data_split)

# splitting the training into the validation set and actual training set
val_set <- validation_split(
    data = train_data,
    prop = 3 / 4,
    strata = o3
)
```

### Defining models:

```{r}
# linear model:
lin_mod <-
    linear_reg(
        penalty = tune(),
        mixture = tune()
    ) |>
    set_engine(
        engine = "glmnet",
        num.threads = parallel::detectCores() - 1
    ) |>
    set_mode("regression")

# decision tree model::
dt_mod <-
    decision_tree(
        cost_complexity = tune(),
        tree_depth = tune(),
        min_n = tune()
    ) |>
    set_engine(
        engine = "rpart",
        num.threads = parallel::detectCores() - 1,
        importance = "impurity"
    ) |>
    set_mode("regression")

# random forest model:
rf_mod <-
    rand_forest(
        mtry = tune(),
        trees = tune(),
        min_n = tune()
    ) |>
    set_engine(
        engine = "ranger",
        num.threads = parallel::detectCores() - 1,
        importance = "impurity"
    ) |>
    set_mode("regression")
```

### Recipes

```{r}
# linear regression
lin_recipe <-
    recipe(o3 ~ ., data = train_data) |>
    update_role(date, pm10, pm25, new_role = "ID") |>
    step_date(date, features = c("month")) |> # change for new var
    step_time(date, features = c("hour")) |> # change for new var
    step_rm(date) |> # remove date column
    step_dummy(all_nominal_predictors()) |> # change categorical data into the binary 0/1 data
    step_zv(all_predictors()) |> # remove colummns with single values
    step_impute_knn(all_predictors()) |> # imputation of missing values
    step_corr(all_predictors(), threshold = 0.7) # decorelation values

# decision tree
dt_recipe <-
    recipe(o3 ~ ., data = train_data) |>
    update_role(date, pm10, pm25, new_role = "ID") |>
    step_date(date, features = c("month")) |> # change for new var
    step_time(date, features = c("hour")) |> # change for new var
    step_rm(date) |> # remove date column

# random forest
rf_recipe <-
    recipe(o3 ~ ., data = train_data) |>
    update_role(date, pm10, pm25, new_role = "ID") |>
    step_date(date, features = c("month")) |> # change for new var
    step_time(date, features = c("hour")) |> # change for new var
    step_rm(date) |> # remove date column
    step_zv(all_predictors()) |> # remove colummns with single values
    step_impute_knn(all_predictors()) |> # imputation of missing values
```